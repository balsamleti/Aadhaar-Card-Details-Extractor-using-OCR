{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "face_finder = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model = load_model('my_model.h5',custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "                            host='localhost',\n",
    "                            user='root',\n",
    "                            database='aadhaar_card_details',\n",
    "                            charset ='utf8'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_finder.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for x,y,w,h in faces:\n",
    "        cropped_image = img[y-10:y+h+15 , x-10:x+w+15]\n",
    "    return cropped_image\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-94f5277db91c>:15: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "Gender = None\n",
    "Birth = None\n",
    "flag = None\n",
    "Adhaar_Number = None\n",
    "face = None\n",
    "Name = None\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    img = frame.copy()\n",
    "    img1 = frame.copy()\n",
    "    frame = cv2.resize(frame,(224,224),interpolation=cv2.INTER_AREA)\n",
    "    frame = frame /255\n",
    "    frame = frame.reshape(1,224,224,3)\n",
    "    output = model.predict_classes(frame)\n",
    "    if output == [[1]]:\n",
    "        img = cv2.putText(img,'Found', (30,30) , cv2.FONT_HERSHEY_COMPLEX , 1  , (0,255,0) , 2)\n",
    "        cv2.imshow('webcam',img)\n",
    "        \n",
    "        \n",
    "        for i in reader.readtext(img1):\n",
    "            if i[2]>0.40 or ((i[1].replace(' ','')).isnumeric() and Adhaar_Number == None and len(i[1])==14):\n",
    "                try:\n",
    "                    if ((i[1].replace(' ','')).isalpha() and Name == None and (i[1].replace(' ','')).lower() not in 'governmentofindia' and len(i[1]) > 7) :\n",
    "                        frame = cv2.rectangle(frame,tuple(i[0][0]),(i[0][0][0]+250,i[0][0][1]+170),(0,255,0),3)\n",
    "                        Name = i[1]\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                if ((i[1].replace('/',''))).isnumeric() and Birth == None and len(i[1])>= 4 and int((i[1].replace('/',''))[-4:]) < 2019 and len(i[1].replace('/','')) <=8  :\n",
    "                    Birth = i[1]\n",
    "\n",
    "                \n",
    "                if ((i[1]=='Male' or i[1] == 'Female') and Gender == None) :\n",
    "                    Gender = i[1]    \n",
    "                \n",
    "                \n",
    "                if ((i[1].replace(' ','')).isnumeric() and Adhaar_Number == None and len(i[1])>=12):\n",
    "                    Adhaar_Number = i[1]\n",
    "                \n",
    "                if face is None:\n",
    "                    face = face_extractor(img1)\n",
    "            \n",
    "            \n",
    "                if (Name != None and Gender != None and Birth != None and Adhaar_Number != None and face is not None ):\n",
    "                    print(f'Name : {Name}')\n",
    "                    print(f'Birth : {Birth}')\n",
    "                    print(f'Gender : {Gender}')\n",
    "                    print(f'Adhaar_Number : {Adhaar_Number}')\n",
    "                    plt.imshow(face[:,:,::-1])\n",
    "                    plt.show()\n",
    "                    print()\n",
    "                    print('is it correct??')\n",
    "                    print('Enter yes or no')\n",
    "                    ans = input()\n",
    "                    if ans == 'yes':\n",
    "                        face_encoded = cv2.imencode('.jpg', face)[1].tostring()\n",
    "                        if conn.is_connected():\n",
    "                            '''\n",
    "                            Check if this table exits. If not, then create a new one.\n",
    "                            '''\n",
    "                            print('Database Connected')\n",
    "                            mycursor = conn.cursor()\n",
    "                            mycursor.execute(\"\"\"\n",
    "                                SELECT COUNT(*)\n",
    "                                FROM information_schema.tables\n",
    "                                WHERE table_name = 'aadhaar_card_details_table'\n",
    "                                \"\"\")\n",
    "                            if mycursor.fetchone()[0] != 1:\n",
    "                                print('Table Not Found')\n",
    "                                print('Creating New Table')\n",
    "                                mycursor.execute(\"CREATE TABLE aadhaar_card_details_table (Aadhaar_Number VARCHAR (255) PRIMARY KEY, Name VARCHAR (255), Birth VARCHAR (255), Gender VARCHAR (255), img LONGBLOB NOT NULL)\")\n",
    "                                conn.commit()\n",
    "                            else:\n",
    "                                print('Table Found')\n",
    "        \n",
    "                            sql = \"INSERT INTO aadhaar_card_details_table (Aadhaar_Number, Name, Birth, Gender, img) VALUES (%s, %s, %s, %s, %s)\"\n",
    "                            val = (Adhaar_Number, Name, Birth, Gender, face_encoded)\n",
    "                            try:\n",
    "                                mycursor.execute(sql, val)\n",
    "                            except mysql.connector.IntegrityError:\n",
    "                                print(f'{Adhaar_Number} already present')\n",
    "                                print('Failed to Store in Database')\n",
    "                                conn.commit()\n",
    "                                mycursor.close()\n",
    "                                flag = 0\n",
    "                                break\n",
    "                            conn.commit()\n",
    "                            mycursor.close()\n",
    "                            print('All Details Stored in Database')\n",
    "                    \n",
    "                        flag = 0\n",
    "                        break\n",
    "                    else:\n",
    "                        Name = None\n",
    "                        Birth = None\n",
    "                        Gender = None\n",
    "                        face = None\n",
    "                        Adhaar_Number = None\n",
    "    \n",
    "    #cv2.imshow('web',frame)\n",
    "    else:\n",
    "        cv2.putText(img,'No Aadhaar Card Found', (30,30) , cv2.FONT_HERSHEY_COMPLEX , 1 , (255,0,0) , 2)\n",
    "        cv2.imshow('webcam',img)\n",
    "    \n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) == 13 or flag==0:  \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Check face image is stored\n",
    "mycursor = conn.cursor()\n",
    "query = 'SELECT img FROM aadhaar_card_details_table WHERE Aadhaar_Number=\"XXXX XXXX XXXX\"'\n",
    "mycursor.execute(query)\n",
    "STRING_FROM_DATABASE = mycursor.fetchone()\n",
    "nparr = np.fromstring(STRING_FROM_DATABASE[0], np.uint8)\n",
    "img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
